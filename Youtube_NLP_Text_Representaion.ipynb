{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PradipNichite/Youtube-Tutorials/blob/main/Youtube_NLP_Text_Representaion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rynjIW1f87JV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn import metrics\n",
        "\n",
        "import string\n",
        "import spacy\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "e_gu1HyO9GLv",
        "outputId": "1e20c635-ff4c-4475-ab6a-787f0631c4f3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id                                       comment_text  toxic  \\\n",
              "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
              "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
              "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
              "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
              "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
              "\n",
              "   severe_toxic  obscene  threat  insult  identity_hate  \n",
              "0             0        0       0       0              0  \n",
              "1             0        0       0       0              0  \n",
              "2             0        0       0       0              0  \n",
              "3             0        0       0       0              0  \n",
              "4             0        0       0       0              0  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv(\"./toxic-comments-dataset/train.csv\",on_bad_lines='skip', engine=\"python\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        comment_text  toxic\n",
              "0  Explanation\\nWhy the edits made under my usern...      0\n",
              "1  D'aww! He matches this background colour I'm s...      0\n",
              "2  Hey man, I'm really not trying to edit war. It...      0\n",
              "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
              "4  You, sir, are my hero. Any chance you remember...      0"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Selecting needed variables from the dataframe\n",
        "data = data[['comment_text','toxic']]\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(159571, 2)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'else', 'and', 'noone', 'meanwhile', 'was', 'this', 'very', 'on', 'themselves', 'empty', 'thereby', 'whereby', 'her', 'still', 'forty', 'seem', 'myself', 'nor', 'keep', 'please', 'whoever', 'enough', 'own', 'anywhere', 'seeming', 'last', 'two', 'yourself', 'same', 'â€˜m', 'really', 'with', 'never', 'should', 'until', 'might', 'hundred', 'hers', 'up', 'had', 'why', 'sometimes', 'â€™re', 'where', 'via', \"'s\", 'then', 'somewhere', 'am', 'being', 'not', 'each', 'from', 'have', 'name', 'others', 'everyone', 'rather', 'fifteen', 'â€˜ll', 'my', 'into', 'thence', 'since', 'give', 'out', 'â€˜re', 'part', 'â€˜d', 'i', 'take', 'often', 'nowhere', 'nevertheless', 'â€™m', 'hereby', \"'ve\", 'bottom', 'â€™s', 'â€˜s', 'do', 'least', 'third', 'almost', 'five', 'â€˜ve', 'beforehand', 'all', 'hereupon', 'six', 'whenever', 'twelve', 'â€™d', 'more', 'yet', 'can', 'behind', 'latter', 'made', 'ourselves', 'during', 'otherwise', 'is', 'thereafter', 'when', 'too', 'before', 'in', 'though', 'across', 'to', 'here', 'as', 'onto', 'move', 'the', 'other', 'besides', 'whither', 'beside', 'several', 'nâ€˜t', 'somehow', 'about', 'put', 'of', 'various', 'together', 'full', 'toward', 'hereafter', \"'m\", 'its', 'sixty', 'has', 'be', 'whether', 'serious', 'hence', 'his', 'beyond', 'will', 'around', 'another', 'every', 'even', 'yourselves', 'ever', 'along', 'make', 'seems', 'none', 'she', 'me', 'except', 'ca', 'whence', 'wherein', 'that', 'first', 'only', \"n't\", 'yours', 'used', 'became', 'no', 'already', 'show', 'anyway', 'are', 'much', 'perhaps', 'without', 'less', 'a', 'him', 'indeed', 'again', 'towards', 'well', 'there', 'upon', 'herself', 'eight', 'must', 'because', 'itself', 'but', 'sometime', 'alone', 'per', 'also', 'doing', 'may', 'an', 'within', 'say', 'it', 'below', 'namely', 'anyhow', 'unless', 'down', 'go', 'we', 'see', 'although', 'those', 'thru', 'always', 'nobody', 'our', 'your', 'thereupon', 'many', 'by', 'among', 'which', 'us', 'for', 'did', 'therein', 'been', \"'d\", 'due', 'seemed', 'either', 'becomes', 'how', 'after', \"'ll\", 'against', 'one', 'just', 'becoming', 'throughout', 'any', 'everything', 'three', 'neither', 'could', 'them', 'mine', 'ours', 'whatever', 'amongst', 'moreover', 'once', 'cannot', 'himself', 'some', 'amount', 'they', 'were', 'thus', 'herein', 'former', 'eleven', 'so', 'something', 'now', 'side', 'nine', 'under', 'does', 'elsewhere', 'twenty', 'who', 'whose', 'mostly', 'four', 'he', 'between', 'than', 'would', 'someone', 'whole', 'call', 'whereupon', 'done', 'get', 'most', 'what', 'whereafter', 'top', 'formerly', 'everywhere', 'such', 'while', 'above', 're', 'further', 'next', 'wherever', 'over', 'using', 'through', 'nâ€™t', 'however', 'quite', 'regarding', 'at', 'fifty', 'both', 'nothing', 'these', 'few', 'â€™ll', 'you', 'or', 'latterly', 'their', 'â€™ve', 'if', 'anyone', 'off', \"'re\", 'ten', 'whereas', 'front', 'anything', 'whom', 'afterwards', 'therefore', 'back', 'become'}\n"
          ]
        }
      ],
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "stop_words = nlp.Defaults.stop_words\n",
        "print(stop_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7V1TAxcI-jec",
        "outputId": "ba404283-3d76-44b0-ea3e-2201f49fd997"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ]
        }
      ],
      "source": [
        "punctuations = string.punctuation\n",
        "print(punctuations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ## Creating Tokenizer function\n",
        "# def spacy_tokenizer(sentence):\n",
        "\n",
        "#     doc = nlp(sentence)\n",
        "\n",
        "#     mytokens = [word.lemma_.lower().strip() for word in doc]\n",
        "\n",
        "#     print(mytokens)\n",
        "\n",
        "#     mytokens = [word for word in mytokens if word not in stop_words and word not in punctuations]\n",
        "#     print(mytokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['hi', 'i', 'be', 'work', 'on', 'a', 'project', '!', '!']\n",
            "['hi', 'work', 'project']\n"
          ]
        }
      ],
      "source": [
        "# spacy_tokenizer('Hi I am working on a project!!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpoOBYrk-rSl"
      },
      "outputs": [],
      "source": [
        "# Creating our tokenizer function\n",
        "def spacy_tokenizer(sentence):\n",
        "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
        "    doc = nlp(sentence)\n",
        "\n",
        "\n",
        "\n",
        "    # print(doc)\n",
        "    # print(type(doc))\n",
        "\n",
        "    # Lemmatizing each token and converting each token into lowercase\n",
        "    mytokens = [ word.lemma_.lower().strip() for word in doc ]\n",
        "\n",
        "    # print(mytokens)\n",
        "\n",
        "    # Removing stop words\n",
        "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
        "\n",
        "    # return preprocessed list of tokens\n",
        "    return mytokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-sWGc8I-zS8",
        "outputId": "61c60497-bb1c-432e-bfda-b934b3c319f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I am eating apple ?\n",
            "<class 'spacy.tokens.doc.Doc'>\n",
            "['i', 'be', 'eat', 'apple', '?']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['eat', 'apple']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentence = \"I am eating apple ?\"\n",
        "spacy_tokenizer(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LPUz0CM-2jb"
      },
      "outputs": [],
      "source": [
        "count_vector = CountVectorizer(tokenizer = spacy_tokenizer)\n",
        "# tfidf_vector = TfidfVectorizer(tokenizer = spacy_tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEu71pvw_DkM",
        "outputId": "22508fd5-d677-43a4-f63b-8065902d868a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 0, 1, 0],\n",
              "       [0, 1, 0, 1]])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vector.fit_transform([\"I am eating apple, I like apple\",\"I am playing cricket\"]).toarray() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_oVh5fb2b2y",
        "outputId": "a4246423-0740-48a1-b409-39b74dd6772d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['apple', 'cricket', 'eat', 'play'], dtype=object)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vector.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXf7_6V6_Hhc",
        "outputId": "820d1887-5457-419b-f29c-0d6abb4d9427"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'eat': 2, 'apple': 0, 'play': 3, 'cricket': 1}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vector.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qec8nyso_L7s"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = data['comment_text'] # the features we want to analyze\n",
        "ylabels = data['toxic'] # the labels, or answers, we want to test against\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.2,stratify=ylabels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGUCTrII_ZTj"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hGUZTMq_kIL"
      },
      "outputs": [],
      "source": [
        "X_train_vetcors= count_vector.fit_transform(X_train)\n",
        "X_test_vetcors= count_vector.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6I17ZFaAlMh",
        "outputId": "87acf4d2-01e3-47a7-90cd-194b907eab45"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(800, 5783)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_vetcors.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGLMunlMAoQR",
        "outputId": "6f1548e4-2058-4b99-908d-9295a74bb205"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(200, 5783)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test_vetcors.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KFEVYJr_H8k",
        "outputId": "7b346096-22fa-4554-e18b-df130b19a9c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_vetcors.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1IfdHPiBmEU",
        "outputId": "87d01f31-abce-4bff-d9cc-aa2d5e63905c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier.fit(X_train_vetcors,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7IrEWeA_07S",
        "outputId": "91d33860-c05b-4d65-d4ed-7ab31e566cbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Accuracy: 0.845\n",
            "Logistic Regression Precision: 0.8709677419354839\n",
            "Logistic Regression Recall: 0.81\n"
          ]
        }
      ],
      "source": [
        "predicted = classifier.predict(X_test_vetcors)\n",
        "print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
        "print(\"Logistic Regression Precision:\",metrics.precision_score(y_test, predicted))\n",
        "print(\"Logistic Regression Recall:\",metrics.recall_score(y_test, predicted))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCejEw89_7Pi"
      },
      "outputs": [],
      "source": [
        "tfidf_vector = TfidfVectorizer(tokenizer = spacy_tokenizer)\n",
        "X_train_vetcors= tfidf_vector.fit_transform(X_train)\n",
        "X_test_vetcors= tfidf_vector.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0CU5yZrDOz-",
        "outputId": "b1ee91ab-980a-48f6-d193-473f30eca01f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Accuracy: 0.86\n",
            "Logistic Regression Precision: 0.9090909090909091\n",
            "Logistic Regression Recall: 0.8\n"
          ]
        }
      ],
      "source": [
        "classifier = LogisticRegression()\n",
        "classifier.fit(X_train_vetcors,y_train)\n",
        "predicted = classifier.predict(X_test_vetcors)\n",
        "print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
        "print(\"Logistic Regression Precision:\",metrics.precision_score(y_test, predicted))\n",
        "print(\"Logistic Regression Recall:\",metrics.recall_score(y_test, predicted))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpnD_5ipD7TF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOFJXXZC8Ax/+sCG7sdvvo6",
      "collapsed_sections": [],
      "include_colab_link": true,
      "mount_file_id": "1FO8mTz3bgIXdnyfVV5PNY5qj0sJJLGOM",
      "name": "Youtube NLP Text Representaion.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('nlp')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "2c8084c65e210ac80286b37f95520e6539b9c1b96da2c782bc032c2b0e58e412"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
